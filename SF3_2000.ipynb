{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from census import Census\n",
    "from us import states\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import csv\n",
    "from functools import reduce\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert your census api key here below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Census(\"4c26aa6ebbaef54a55d3903212eabbb506ade381\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2000 SF3 Variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "P006001 - Total Population\n",
    "P007003 - Total White Population\n",
    "P007004 - Total Non-Hispanic Black Population\n",
    "P006005 - Total Asian Pouplation\n",
    "P007010 - Total Hispanic Population\n",
    "\n",
    "P021013 - Total Foreign Born\n",
    "\n",
    "H062001 - Total Rent\n",
    "H062002 - Paying Rent With no Cash\n",
    "H063001 - Paying Cash Rent\n",
    "\n",
    "H085001 - Median value of owner occupied house\n",
    "\n",
    "H007001 - Total Occupied Housing Units\n",
    "H007002 - Owner Occupied Housing Units\n",
    "H007003 - Renter Occupied Housing Units\n",
    "\n",
    "H034001 - Total Housing Units\n",
    "H034009 + H034010 - Units Built before 1950\n",
    "\n",
    "H038009 - Total Renter Occupied\n",
    "H038014 + H038015 - Number of Renters that Moved In before 1979\n",
    "\n",
    "H069001 - Renter specified Housing Units\n",
    "H069007 + H069008 + H069009 + H069010 Total Renters with Rent Burden over 30 percent\n",
    "\n",
    "HCT001005 + HCT001012 + HCT001018 + HCT001031 + HCT001038 + HCT001044 - Total Households with Own Children\n",
    "\n",
    "P032001 - People over 16 y/o that travels to work\n",
    "P032002 - Travel time less than 30 min\n",
    "P032005 - Travel time between 30-45 min\n",
    "P032008 - Travel time between 45-60 min\n",
    "P032011 - travel time more than 60 min\n",
    "\n",
    "P030003 - Drove Car alone\n",
    "P030004 + P030005 + P030012 + P030013 + P030014 + P030015 - Other means of transport\n",
    "\n",
    "P052001 - Total number of households\n",
    "\n",
    "P052002 - Less than 10k\n",
    "P052003 - Between 10k - 15k\n",
    "P052004 - Between 15k - 20k\n",
    "P052005 - Between 20k - 25k\n",
    "P052006 - Between 25k - 30k\n",
    "P052007 - Between 30k - 35k\n",
    "P052008 - Between 35k - 40k\n",
    "P052009 - Between 40k - 45k\n",
    "P052010 - Between 45k - 50k\n",
    "P052011 - Between 50k - 60k\n",
    "P052012 - Between 60k - 75k\n",
    "P052013 - Between 75k - 100k\n",
    "P052014 - Between 100k - 125k\n",
    "P052015 - Between 125k - 150k\n",
    "P052016 - Between 150k - 200k\n",
    "P052017 - 200k or more\n",
    "\n",
    "P053001 - Median Household Income\n",
    "\n",
    "P037001 - Total Population 25 and over\n",
    "P037015 - Total Male Population with a bachelor's Degree\n",
    "P037032 - Total Female Population with a bachelor's Degree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the buckets for variables that are separeted into bins like income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 60000, 75000, 100000, 125000, 150000, 200000,1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert the variables you want to download. The second part is just so it is automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['P0060', 'H0620', 'H0630', 'H0850', 'H0070', 'P0520', 'P0530', 'P0370']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=[]\n",
    "for i in variables:\n",
    "    var.append(i+'01')\n",
    "    if ((i == 'P0060') | (i == 'H0620') | (i == 'H0070')):\n",
    "        var.append(i+'02')\n",
    "    if i == 'H0070':\n",
    "        var.append(i+'03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.append('NAME')\n",
    "for i in range(2,10):\n",
    "    var.append('P05200'+str(i))\n",
    "for i in range(10,18):\n",
    "    var.append('P0520'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.append('P037015')\n",
    "var.append('P037032')\n",
    "var.append('P007004')\n",
    "var.append('P006005')\n",
    "var.append('P007010')\n",
    "var.append('P021013')\n",
    "var.append('H038009')\n",
    "var.append('H038014')\n",
    "var.append('H038015')\n",
    "var.append('H069001')\n",
    "var.append('H069007')\n",
    "var.append('H069008')\n",
    "var.append('H069009')\n",
    "var.append('H069010')\n",
    "var.append('HCT001005')\n",
    "var.append('HCT001012')\n",
    "var.append('HCT001018')\n",
    "var.append('HCT001031')\n",
    "var.append('HCT001038')\n",
    "var.append('HCT001044') \n",
    "var.append('P032001')\n",
    "var.append('P032002')\n",
    "var.append('P032005')\n",
    "var.append('P032008')\n",
    "var.append('P032011')\n",
    "var.append('H034009')\n",
    "var.append('H034010')\n",
    "var.append('H034001')\n",
    "var.append('P030003')\n",
    "var.append('P030004')\n",
    "var.append('P030005')\n",
    "var.append('P030012')\n",
    "var.append('P030013')\n",
    "var.append('P030014')\n",
    "var.append('P030015')\n",
    "var.append('P007003')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the state and insert its code (as a string number)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alabama\t        01  AL\n",
    "Alaska\t        02  AK\n",
    "Arizona\t        04  AZ\n",
    "Arkansas\t    05  AR\n",
    "California\t    06  CA\n",
    "Colorado\t    08  CO\n",
    "Connecticut\t    09\tCT\n",
    "Delaware\t    10\tDE\n",
    "D.C.         \t11\tDC\n",
    "Florida\t        12\tFL\n",
    "Georgia\t        13\tGA\n",
    "Hawaii\t        15\tHI\n",
    "Idaho\t        16\tID\n",
    "Illinois\t    17\tIL\n",
    "Indiana\t        18\tIN\n",
    "Iowa\t        19\tIA\n",
    "Kansas\t        20\tKS\n",
    "Kentucky\t    21\tKY\n",
    "Louisiana\t    22\tLA\n",
    "Maine\t        23\tME\n",
    "Maryland\t    24\tMD\n",
    "Massachusetts\t25\tMA\n",
    "Michigan\t    26\tMI\n",
    "Minnesota\t    27\tMN\n",
    "Mississippi\t    28\tMS\n",
    "Missouri\t    29\tMO\n",
    "Montana\t        30\tMT\n",
    "Nebraska\t    31\tNE\n",
    "Nevada\t        32\tNV\n",
    "New Hampshire\t33\tNH\n",
    "New Jersey\t    34\tNJ\n",
    "New Mexico\t    35\tNM\n",
    "New York\t    36\tNY\n",
    "North Carolina\t37  NC\n",
    "North Dakota\t38  ND\n",
    "Ohio\t        39  OH \n",
    "Oklahoma\t    40  OK\n",
    "Oregon\t        41  OR\n",
    "Pennsylvania\t42  PA\n",
    "Rhode Island\t44  RI\n",
    "South Carolina\t45  SC\n",
    "South Dakota\t46  SD\n",
    "Tennessee\t    47  TN\n",
    "Texas\t        48  TX\n",
    "Utah\t        49  UT\n",
    "Vermont\t        50  VT\n",
    "Virginia\t    51  VA\n",
    "Washington\t    53  WA\n",
    "West Virginia\t54  WV\n",
    "Wisconsin\t    55  WI\n",
    "Wyoming\t        56  WY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = '09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query='state:{} county:*'.format(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dic = c.sf3.get(var, geo = {'for': 'tract:*',\n",
    "                       'in': sql_query}, year = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_2='state:{}'.format(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = c.sf3.get('P053001', geo = {'for': 'county:*',\n",
    "                       'in': sql_query_2}, year = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold = pd.DataFrame(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('variables_' + state + '.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the thresholds for each of the counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = df.county.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = {}\n",
    "counties = counties.fromkeys(county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(columns)-3):\n",
    "    if columns[i]!='NAME':\n",
    "        df[columns[i]] = df[columns[i]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold = df_threshold.rename(columns={'P053001':'median'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold = df_threshold.set_index('county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold = df_threshold.drop(columns='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold['median'] = df_threshold['median'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_typo['vvli_threshold']=0.3*df_typo['median']\n",
    "df_threshold['vli_threshold'] = 0.5*df_threshold['median']\n",
    "df_threshold['li_threshold'] = 0.8*df_threshold['median']\n",
    "df_threshold['mi_threshold'] = 1.2*df_threshold['median']\n",
    "df_threshold['mhi_threshold'] = 1.5*df_threshold['median']\n",
    "df_threshold['hi_threshold'] = 2*df_threshold['median']\n",
    "df_threshold['vhi_threshold'] = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the different typologies based on each county's median income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.zeros((len(county),len(buckets)-1))\n",
    "for j in range(0, len(counties)):\n",
    "    col = 1\n",
    "    for i in range(0, len(buckets)-1):\n",
    "        if buckets[i+1] < df_threshold.iloc[j, col]:\n",
    "            table[j, i] = True\n",
    "        else:\n",
    "            table[j, i] = (df_threshold.iloc[j, col] - buckets[i]) / (buckets[i+1] - buckets[i])\n",
    "            col = col+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values=[]\n",
    "for i in county:\n",
    "    with open('variables_'+state+'.csv', 'r') as fi:\n",
    "        reader = csv.DictReader(fi)\n",
    "        def creator(reader, c):\n",
    "            bt = filter(lambda x: x['county'] == c, reader)\n",
    "            return (list(bt))\n",
    "        value = creator(reader, i)\n",
    "    values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_typo = []\n",
    "for j in range(0, len(county)):\n",
    "    for i in range(0, len(values[j])):\n",
    "        typo = []\n",
    "        summ = 0\n",
    "        for col in range(0,len(buckets)-1):\n",
    "            if ((table[j, col] == 1) & (values[j][i][var[9]]!='0')):\n",
    "                summ = summ + float(values[j][i][var[13+col]])/float(values[j][i][var[9]])\n",
    "            else:\n",
    "                if values[j][i][var[9]]!='0':\n",
    "                    summ = summ + float(values[j][i][var[13+col]])*table[j, col]/float(values[j][i][var[9]])\n",
    "                    typo.append(summ)\n",
    "                    summ = float(values[j][i][var[13+col]])*(1-table[j, col])/float(values[j][i][var[9]])\n",
    "        typo.append(summ)\n",
    "        income_typo.append(typo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(income_typo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.rename(columns={0:'vli_00', 1:'li_00', 2:'mi_00', 3:'mhi_00', 4:'hi_00', 5:'vhi_00'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_00'] = df['P037015'] + df['P037032']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['burden_00'] = df['H069007'] + df['H069008'] + df['H069009'] + df['H069010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commute_med_00'] = df['P032005'] + df['P032008']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['burden_00'] = df['H069007'] + df['H069008'] + df['H069009'] + df['H069010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hhwchild_00']= df['HCT001005'] + df['HCT001012'] + df['HCT001018'] + df['HCT001031'] + df['HCT001038'] + df['HCT001044']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['per_units_pre50_00'] = (df['H034009'] + df['H034010']) / df['H034001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['per_car_commute_00'] = df['P030003'] / (df['P030003'] + df['P030004'] + df['P030005'] + df['P030012'] + \n",
    "                                                  df['P030013'] + df['P030014'] + df['P030015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "moe_names = ['per_col_00', 'per_rent_00', 'per_owners_00', 'per_nonwhite_00', 'per_black_00', 'per_asian_00', \n",
    "             'per_latino_00', 'per_hhwchild_00',  'per_commute_low_00', 'per_commute_med_00', 'per_commute_high_00',\n",
    "            'per_burden_00', 'per_foreign_00']\n",
    "\n",
    "moe_dividend = ['col_00', 'H007003', 'H007002', 'P007003', 'P007004', 'P006005', 'P007010', 'hhwchild_00', 'P032002',\n",
    "               'commute_med_00', 'P032011', 'burden_00', 'P021013']\n",
    "\n",
    "moe_divisor = ['P037001', 'H007001', 'H007001', 'P006001', 'P006001', 'P006001', 'P006001', 'H007001', 'P032001', \n",
    "               'P032001', 'P032001', 'H069001', 'P006001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(moe_names)):\n",
    "    if i!=3:\n",
    "        df_final[moe_names[i]] = df[moe_dividend[i]]/df[moe_divisor[i]]\n",
    "    else:\n",
    "        df_final[moe_names[i]] = 1 - df[moe_dividend[i]]/df[moe_divisor[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'P052001':'hh_00', 'H063001':'mrent_00', 'P053001':'hinc_00', \n",
    "                        'H085001':'mhval_00', 'H007001':'hu_00', 'P006001':'pop_00'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.join(df[['hh_00', 'mrent_00', 'hinc_00', 'mhval_00', 'hu_00', 'pop_00', 'NAME', 'state', 'county',\n",
    "                             'tract']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolating the data to fit 2010 census tract boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['GEOid2'] = df_final['state'] + df_final['county'] + df_final['tract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['GEOid2'] = df_final.GEOid2.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00 = pd.read_csv('crosswalk_2000_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00['state'] = df_crosswalk_00.trtid00.apply(lambda x: str(x)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00_red = df_crosswalk_00[df_crosswalk_00.state==state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00_red = df_crosswalk_00_red.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "id00 = list(df_crosswalk_00_red.trtid00.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "id10 = list(df_crosswalk_00_red.trtid10.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_len = len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_len = len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of information lost is: 0.9768009768009768\n"
     ]
    }
   ],
   "source": [
    "print('The percentage of information lost is: {}'.format((prev_len-final_len)*100/prev_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the SF3 1990 final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['GEOid2'] = df_final['state'] + df_final['county'] + df_final['tract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['GEOid2'] = df_final.GEOid2.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(columns='NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(state+'_2000_variables.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolating the data to fit 2010 census tract boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00 = pd.read_csv('crosswalk_2000_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00['state'] = df_crosswalk_00.trtid00.apply(lambda x: str(x)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00_red = df_crosswalk_00[df_crosswalk_00.state==state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00_red = df_crosswalk_00_red.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosswalk_00_red['trtid10'] = df_crosswalk_00_red['trtid10'].apply(lambda x: str(x))\n",
    "df_crosswalk_00_red['trtid00'] = df_crosswalk_00_red['trtid00'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "id00 = list(df_crosswalk_00_red.trtid00.unique())\n",
    "id10 = list(df_crosswalk_00_red.trtid10.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning total weight sums that exceeds an stablished threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_total = 0\n",
    "for i in id10:\n",
    "    weight_total = np.sum(df_crosswalk_00_red[df_crosswalk_00_red.trtid10==i].weight)\n",
    "    if ((weight_total<1-threshold)|(weight_total>1+threshold)):\n",
    "        id10.remove(i)\n",
    "        df_crosswalk_00_red = df_crosswalk_00_red[df_crosswalk_00_red.trtid10!=i]\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l=[]\n",
    "for i in range(0,len(df_crosswalk_00_red)):\n",
    "    l.append(df_crosswalk_00_red['weight'][i]/weight_total[df_crosswalk_00_red.trtid10[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_crosswalk_00_red['weight'] = l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_crosswalk_00_red = df_crosswalk_00_red.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_final[df_final.GEOid2.isin(id10)].to_csv(state+'_2000_variables_clean.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tract_id10 = {}\n",
    "tract_id10 = tract_id10.fromkeys(id10)\n",
    "for i in range(0, len(df_crosswalk_00_red)):\n",
    "        if (type(tract_id10[df_crosswalk_00_red['trtid10'][i]])==list):\n",
    "            tract_id10[df_crosswalk_00_red['trtid10'][i]].append(df_crosswalk_00_red['trtid00'][i])\n",
    "        if (type(tract_id10[df_crosswalk_00_red['trtid10'][i]])!=list):\n",
    "            tract_id10[df_crosswalk_00_red['trtid10'][i]] = [df_crosswalk_00_red['trtid00'][i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_dic = {}\n",
    "weight_dic = weight_dic.fromkeys(id10)\n",
    "for i in id10:\n",
    "    weight_dic[i] = weight_dic.fromkeys(tract_id10[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "geoid = df_final[df_final.GEOid2.isin(id10)].GEOid2.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(0,len(df_crosswalk_00_red)):\n",
    "    try:\n",
    "        if ((df_crosswalk_00_red['trtid00'][i] in geoid) & (df_crosswalk_00_red['weight'][i]!=0)):\n",
    "            weight_dic[df_crosswalk_00_red['trtid10'][i]][df_crosswalk_00_red['trtid00'][i]] = df_crosswalk_00_red['weight'][i]\n",
    "        elif ((len(weight_dic[df_crosswalk_00_red['trtid10'][i]])==1)|(df_crosswalk_00_red['weight'][i]!=0)):\n",
    "            weight_dic.pop(df_crosswalk_00_red['trtid10'][i])\n",
    "        else:\n",
    "            weight_dic[df_crosswalk_00_red['trtid10'][i]].pop(df_crosswalk_00_red['trtid00'][i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def cross(dictionary, reader, key, weight):\n",
    "    with open(state+'_2000_variables_clean.csv', 'r') as fi:\n",
    "        reader = csv.DictReader(fi)\n",
    "        bt = list(filter(lambda x: x['GEOid2'] == key, reader))\n",
    "        nt = np.fromiter(bt[0].values(), dtype = float)[:-4]*weight\n",
    "    return (nt)\n",
    "arr = map(lambda j: reduce((lambda x,y: x+y),(map(lambda k: cross(weight_dic[j], \n",
    "                                              reader, k, weight_dic[j][k]), \n",
    "                                             list(map(lambda x: x, weight_dic[j]))))), \n",
    "                                             list(map(lambda j: j, weight_dic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df_final_crosswalk = pd.DataFrame(list(arr), columns = df_final.iloc[:,:-4].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_final_crosswalk['GEOid2'] = list(map(lambda j: j, weight_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('The percentage of information lost is: {}'.format((len(df_final)-len(df_final_crosswalk))*100/len(df_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the final file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_final_crosswalk.to_csv(state+'_2000_variables_crosswalk.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_final_crosswalk.iloc[:,:6].sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
